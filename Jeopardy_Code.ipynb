{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *       # for datatype conversion\n",
    "from pyspark.sql.functions import *   # for col() function\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "import re\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.ml.feature import MaxAbsScaler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlCtx = SQLContext(sc)\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Jeopardy Calculation\") \\\n",
    "    .config(\"spark.executor.memory\", '2g') \\\n",
    "    .config('spark.executor.cores', '1') \\\n",
    "    .config('spark.cores.max', '1') \\\n",
    "    .config(\"spark.driver.memory\",'1g') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code is to create a function to stem the words from questions with stop words removed\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "def stem(in_vec):\n",
    "    out_vec = []\n",
    "    for t in in_vec:\n",
    "        t_stem = stemmer.stem(t)\n",
    "        out_vec.append(t_stem)       \n",
    "    return out_vec\n",
    "from pyspark.sql.types import *\n",
    "stemmer_udf = udf(lambda x: stem(x), ArrayType(StringType()))\n",
    "\n",
    "#reading in the jeopardy data set\n",
    "jeopardy = spark.read.json(\"JEOPARDY_QUESTIONS1-Copy1.json\")\n",
    "j_categoryCount = jeopardy.groupBy(\"category\").count()\n",
    "#This is the number of categories in the dataset which have greater than 100 observations\n",
    "count100 = j_categoryCount.sort(desc(\"count\")).filter(j_categoryCount[\"count\"] > 100).count()\n",
    "#This is a list of all categories which have a count greater than 100, comes out to be 145 categories\n",
    "top_categories = list(j_categoryCount.sort(desc(\"count\")).select(\"category\").limit(count100).toPandas().category)\n",
    "#new dataset that only contains categories that have greater than 100 osbervations\n",
    "jeo_f = jeopardy.where(col(\"category\").isin(top_categories))\n",
    "#stripping punctuation, tokenizing, stop word removing, and stemming for the modified dataset\n",
    "jeo_fpunc = jeo_f.withColumn(\"stripped\", f.regexp_replace(f.col(\"question\"), \"[\\!@#$%^&*)(><,';:]\", \"\"))\n",
    "jeo_fpunc.cache()\n",
    "tokenizer = Tokenizer(inputCol = \"stripped\", outputCol = \"words\")\n",
    "tokenized_f = tokenizer.transform(jeo_fpunc)\n",
    "tokenized_f.cache()\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "jeo_fStopRemoved = remover.transform(tokenized_f)\n",
    "jeo_fStopRemoved.cache()\n",
    "jeo_fStemmed = jeo_fStopRemoved.withColumn(\"stemmed\", stemmer_udf(\"filtered\"))\n",
    "jeo_fStemmed.cache()\n",
    "#shows what the new dataset looks like\n",
    "jeo_fStemmed.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on 145 Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and test split\n",
    "training,test = jeo_fStemmed.randomSplit([0.8,0.2], seed = 1) \n",
    "#pipeline that goes through hashing tf, idf, indexing, and naive bayes algorithm\n",
    "#also uses multiple smoothing parameters for cross validation\n",
    "hashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\", numFeatures = 50000)\n",
    "idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\")\n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"label\")\n",
    "nb = NaiveBayes(modelType=\"multinomial\", featuresCol = \"features\", labelCol = \"label\")\n",
    "\n",
    "pipelineNB = Pipeline(stages=[hashingTF,idf,indexer,nb])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(nb.smoothing, [0.1,1.0,5.0,10.0,50.0]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipelineNB,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=5)\n",
    "cvModel = crossval.fit(training)\n",
    "\n",
    "prediction = cvModel.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "#output accuracy metric for our model\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "#output f1 score metric for our model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"f1\")\n",
    "f1 = evaluator.evaluate(prediction)\n",
    "print(\"Test set f1 = \" + str(f1))\n",
    "#training accuracy for all smoothing parameters\n",
    "cvModel.avgMetrics\n",
    "#shows counts for all predictions on test set\n",
    "prediction.groupBy('prediction').count().sort(desc(\"prediction\")).show(145)\n",
    "#shows category and question for the prediction category '1'\n",
    "prediction.filter(prediction['prediction'] == 1).select(\"category\",\"question\").sort(\"category\") \\\n",
    "    .show(424,truncate=False)\n",
    "#shows the category and its respective label\n",
    "prediction.select(\"label\",\"category\").sort(asc(\"label\")).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Computer Defined Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\", numFeatures=50000)\n",
    "featurizedData = hashingTF.transform(jeo_fStemmed)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData.cache()\n",
    "#training,test split for modified dataset\n",
    "training,test = rescaledData.randomSplit([0.8,0.2], seed = 1)\n",
    "# 10 computer defined clusters\n",
    "bkm10 = BisectingKMeans().setK(10).setSeed(1)\n",
    "modelf = bkm10.fit(rescaledData)\n",
    "bkmclustf = modelf.transform(rescaledData)\n",
    "bkmclustf.groupBy('prediction').count().sort(desc(\"prediction\")).show(10)\n",
    "bkmclustf.select(\"prediction\").write.csv(\"bkmf2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import computer defines clusters\n",
    "comp_col = spark.read.csv(\"bkmf2.csv\")\n",
    "comp_col2 = comp_col.withColumn(\"ID\", monotonically_increasing_id())\n",
    "jeo_h = jeo_g.withColumn(\"ID\", monotonically_increasing_id())\n",
    "jeo_i = jeo_h.join(comp_col2, on=\"ID\").withColumnRenamed(\"_c0\", \"computer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Computer Defined Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and test split\n",
    "training,test = jeo_i.randomSplit([0.8,0.2], seed = 1) \n",
    "#pipeline that goes through hashing tf, idf, indexing, and naive bayes algorithm\n",
    "#also uses multiple smoothing parameters for cross validation\n",
    "hashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\", numFeatures = 50000)\n",
    "idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\")\n",
    "indexer = StringIndexer(inputCol=\"computer\", outputCol=\"label\")\n",
    "nb = NaiveBayes(modelType=\"multinomial\", featuresCol = \"features\", labelCol = \"label\")\n",
    "\n",
    "pipelineNB = Pipeline(stages=[hashingTF,idf,indexer,nb])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(nb.smoothing, [5000, 20000, 30000, 40000, 50000]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipelineNB,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=5)\n",
    "cvModel = crossval.fit(training)\n",
    "\n",
    "\n",
    "prediction = cvModel.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "#output accuracy metric for our model\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "#training accuracy for all smoothing parameters\n",
    "cvModel.avgMetrics\n",
    "#shows counts for all predictions on test set\n",
    "prediction.groupBy('prediction').count().sort(desc(\"prediction\")).show(145)\n",
    "#shows category and question for the prediction cluster '0'\n",
    "prediction.filter(prediction['prediction'] == 0).select(\"category\",\"question\").sort(\"category\") \\\n",
    "    .show(424,truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression on Computer Defined Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and test split\n",
    "training,test = jeo_i.randomSplit([0.8,0.2], seed = 1) \n",
    "#pipeline that goes through hashing tf, idf, indexing, and logistic regression algorithm\n",
    "#also uses multiple regularization parameters for cross validation\n",
    "hashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\", numFeatures = 50000)\n",
    "idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\")\n",
    "indexer = StringIndexer(inputCol=\"computer\", outputCol=\"label\")\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10, elasticNetParam=0.8,\n",
    "                       family=\"multinomial\")\n",
    "\n",
    "pipelineLR = Pipeline(stages=[hashingTF,idf,indexer,lr])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.001,0.0025,0.005,0.0075,.01]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipelineLR,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=5)\n",
    "cvModel = crossval.fit(training)\n",
    "prediction = cvModel.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "#output accuracy metric for our model\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "#training accuracy for all smoothing parameters\n",
    "cvModel.avgMetrics\n",
    "#shows counts for all predictions on test set\n",
    "prediction.groupBy('prediction').count().sort(desc(\"prediction\")).show(145)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Human Defined Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the category of the human labels\n",
    "#created a excel file where we manually grouped together these categories using a key.\n",
    "humanclust = [9, 0, 5, 7, 9, 7, 9, 2, 7, 8, 2, 2, 3, 1, 2, 8, 3, 2, 2, 5, 6, 5, 5, 8, 8, 5, 9, 4, 0, 6,\n",
    "              9, 5, 6, 5, 7, 1, 8, 0, 7, 9, 2, 8, 9, 8, 5, 6, 4, 6, 5, 9, 9, 5, 5, 8, 2, 6, 2, 7, 6, 4,\n",
    "              4, 0, 1, 9, 7, 0, 2, 1, 9, 7, 0, 4, 4, 4, 0, 0, 4, 2, 1, 0, 8, 9, 4, 8, 0, 1, 9, 9, 8, 8,\n",
    "              9, 0, 7, 0, 7, 4, 2, 9, 4, 4, 0, 7, 9, 0, 4, 4, 3, 2, 1, 9, 8, 4, 4, 9, 5, 9, 1, 0, 2, 4,\n",
    "              1, 9, 4, 4, 9, 6, 4, 4, 5, 4, 8, 9, 6, 5, 5, 0, 2, 0, 0, 4, 8, 8, 4, 7, 2]\n",
    "human_udf = udf(lambda x: int(humanclust[top_categories.index(x)]))\n",
    "jeo_g = jeo_fStemmed.withColumn(\"human\", human_udf(jeo_f.category).cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Human Defined Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and test split\n",
    "training,test = jeo_g.randomSplit([0.8,0.2], seed = 1)\n",
    "#pipeline that goes through hashing tf, idf, indexing, and naive bayes algorithm\n",
    "#also uses multiple smoothing parameters for cross validation\n",
    "hashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\", numFeatures = 50000)\n",
    "idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\")\n",
    "indexer = StringIndexer(inputCol=\"human\", outputCol=\"label\")\n",
    "nb = NaiveBayes(modelType=\"multinomial\", featuresCol = \"features\", labelCol = \"label\")\n",
    "\n",
    "pipelineNB = Pipeline(stages=[hashingTF,idf,indexer,nb])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(nb.smoothing, [0.1,1.0,5.0,10.0,50.0, 100]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipelineNB,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=5)\n",
    "cvModel = crossval.fit(training)\n",
    "\n",
    "\n",
    "prediction = cvModel.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "#output accuracy metric for our model\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"f1\")\n",
    "#output f1 score for our model\n",
    "f1 = evaluator.evaluate(prediction)\n",
    "print(\"Test set f1 = \" + str(f1))\n",
    "#training accuracy for all smoothing parameters\n",
    "cvModel.avgMetrics\n",
    "#shows counts for all predictions on test set\n",
    "prediction.groupBy('prediction').count().sort(desc(\"prediction\")).show(145)\n",
    "#shows category and question for the prediction category '0'\n",
    "prediction.filter(prediction['prediction'] == 0).select(\"category\",\"question\").sort(\"category\") \\\n",
    "    .show(424,truncate=False)\n",
    "#shows the label for each human defined cluster\n",
    "prediction.select(\"label\",\"human\").sort(asc(\"human\")).distinct().show()\n",
    "\n",
    "#run multiple cross validations on naive bayes model\n",
    "training,test = jeo_g.randomSplit([0.8,0.2], seed = 123)\n",
    "cvModel = crossval.fit(training)\n",
    "prediction = cvModel.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "cvModel.avgMetrics\n",
    "training,test = jeo_g.randomSplit([0.8,0.2], seed = 300)\n",
    "cvModel = crossval.fit(training)\n",
    "prediction = cvModel.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "\n",
    "\n",
    "cvModel.avgMetrics\n",
    "#end of running multiple cross validations on naive bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression on Human Defined Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and test split\n",
    "training,test = jeo_g.randomSplit([0.8,0.2], seed = 1) \n",
    "#pipeline that goes through hashing tf, idf, indexing, and logistic regression algorithm\n",
    "#also uses multiple regularization parameters for cross validation\n",
    "hashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\", numFeatures = 50000)\n",
    "idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\")\n",
    "indexer = StringIndexer(inputCol=\"human\", outputCol=\"label\")\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10, elasticNetParam=0.8,\n",
    "                       family=\"multinomial\")\n",
    "\n",
    "pipelineLR = Pipeline(stages=[hashingTF,idf,indexer,lr])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.001,0.0025,0.005,0.0075,.01]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipelineLR,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=5)\n",
    "cvModel = crossval.fit(training)\n",
    "prediction = cvModel.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "#output accuracy metric for our model\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "#training accuracy for all smoothing parameters\n",
    "cvModel.avgMetrics\n",
    "#shows counts for all predictions on test set\n",
    "prediction.groupBy('prediction').count().sort(desc(\"prediction\")).show(145)\n",
    "#run multiple cross validations on naive bayes model\n",
    "training,test = jeo_g.randomSplit([0.8,0.2], seed = 123) \n",
    "cvModel = crossval.fit(training)\n",
    "prediction = cvModel.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "cvModel.avgMetrics\n",
    "training,test = jeo_g.randomSplit([0.8,0.2], seed = 300) \n",
    "cvModel = crossval.fit(training)\n",
    "prediction = cvModel.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n",
    "cvModel.avgMetrics\n",
    "#end of running multiple cross validations on naive bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Creating WordClouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from matplotlib import pyplot as mp\n",
    "\n",
    "#this code for wordclouds was replicated for many models and sets of questions that we created, \n",
    "#this is just one example of plenty of wordclouds created. Only show one example because code is repetitive\n",
    "\n",
    "#remember to do pip install wordcloud in terminal\n",
    "\n",
    "#create wordcloud\n",
    "text = prediction.filter(prediction[\"prediction\"] == 9).select(\"question\").toPandas()\n",
    "questions = str(text)\n",
    "wordcloud = WordCloud(max_words=100, width=800, height=400, background_color=\"white\").generate(questions)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "#save wordcloud to a file\n",
    "wordcloud.to_file(\"LR_Human_images/watergeographyLRH.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
