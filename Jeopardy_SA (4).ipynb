{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "#lrModel = lr.fit(training)\n",
    "#predictions = lrModel.transform(test)\n",
    "#predictions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *       # for datatype conversion\n",
    "from pyspark.sql.functions import *   # for col() function\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "import re\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.ml.feature import MaxAbsScaler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlCtx = SQLContext(sc)\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Jeopardy Calculation\") \\\n",
    "    .config(\"spark.executor.memory\", '2g') \\\n",
    "    .config('spark.executor.cores', '1') \\\n",
    "    .config('spark.cores.max', '1') \\\n",
    "    .config(\"spark.driver.memory\",'1g') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "def stem(in_vec):\n",
    "    out_vec = []\n",
    "    for t in in_vec:\n",
    "        t_stem = stemmer.stem(t)\n",
    "        out_vec.append(t_stem)       \n",
    "    return out_vec\n",
    "from pyspark.sql.types import *\n",
    "stemmer_udf = udf(lambda x: stem(x), ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratorty Data Analysis\n",
    "### and Preprocessing for a new dataset where counts are greater than 100 for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the jeopardy data set\n",
    "jeopardy = spark.read.json(\"JEOPARDY_QUESTIONS1-Copy1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+----------------+-----------+------+\n",
      "|  air_date|              answer|            category|            question|           round|show_number| value|\n",
      "+----------+--------------------+--------------------+--------------------+----------------+-----------+------+\n",
      "|2004-12-31|          Copernicus|             HISTORY|'For the last 8 y...|       Jeopardy!|       4680|  $200|\n",
      "|2004-12-31|          Jim Thorpe|ESPN's TOP 10 ALL...|'No. 2: 1912 Olym...|       Jeopardy!|       4680|  $200|\n",
      "|2004-12-31|             Arizona|EVERYBODY TALKS A...|'The city of Yuma...|       Jeopardy!|       4680|  $200|\n",
      "|2004-12-31|         McDonald\\'s|    THE COMPANY LINE|'In 1963, live on...|       Jeopardy!|       4680|  $200|\n",
      "|2004-12-31|          John Adams| EPITAPHS & TRIBUTES|'Signer of the De...|       Jeopardy!|       4680|  $200|\n",
      "|2004-12-31|             the ant|      3-LETTER WORDS|'In the title of ...|       Jeopardy!|       4680|  $200|\n",
      "|2004-12-31|      the Appian Way|             HISTORY|'Built in 312 B.C...|       Jeopardy!|       4680|  $400|\n",
      "|2004-12-31|      Michael Jordan|ESPN's TOP 10 ALL...|'No. 8: 30 steals...|       Jeopardy!|       4680|  $400|\n",
      "|2004-12-31|          Washington|EVERYBODY TALKS A...|'In the winter of...|       Jeopardy!|       4680|  $400|\n",
      "|2004-12-31|      Crate & Barrel|    THE COMPANY LINE|'This housewares ...|       Jeopardy!|       4680|  $400|\n",
      "|2004-12-31|      Jackie Gleason| EPITAPHS & TRIBUTES|  '\"And away we go\"'|       Jeopardy!|       4680|  $400|\n",
      "|2004-12-31|             the cud|      3-LETTER WORDS|'Cows regurgitate...|       Jeopardy!|       4680|  $400|\n",
      "|2004-12-31|Ceylon (or Sri La...|             HISTORY|'In 1000 Rajaraja...|       Jeopardy!|       4680|  $600|\n",
      "|2004-12-31|           Jim Brown|ESPN's TOP 10 ALL...|'No. 1: Lettered ...|       Jeopardy!|       4680|  $600|\n",
      "|2004-12-31|        the UV index|EVERYBODY TALKS A...|'On June 28, 1994...|       Jeopardy!|       4680|  $600|\n",
      "|2004-12-31|              Bulova|    THE COMPANY LINE|'This company's A...|       Jeopardy!|       4680|  $600|\n",
      "|2004-12-31|         Jesse James| EPITAPHS & TRIBUTES|'Outlaw: \"Murdere...|       Jeopardy!|       4680|  $600|\n",
      "|2004-12-31|                 imp|      3-LETTER WORDS|'A small demon, o...|       Jeopardy!|       4680|  $600|\n",
      "|2004-12-31|   the International|             HISTORY|'Karl led the fir...|       Jeopardy!|       4680|  $800|\n",
      "|2004-12-31|        (Lou) Gehrig|ESPN's TOP 10 ALL...|'No. 10: FB/LB fo...|       Jeopardy!|       4680|  $800|\n",
      "|2004-12-31|             Morocco|EVERYBODY TALKS A...|'Africa's lowest ...|       Jeopardy!|       4680|  $800|\n",
      "|2004-12-31|       (Paul) Bonwit|    THE COMPANY LINE|'Edward Teller & ...|       Jeopardy!|       4680|  $800|\n",
      "|2004-12-31|Hattie McDaniel (...| EPITAPHS & TRIBUTES|'1939 Oscar winne...|       Jeopardy!|       4680|$2,000|\n",
      "|2004-12-31|                 era|      3-LETTER WORDS|'In geologic time...|       Jeopardy!|       4680|  $800|\n",
      "|2004-12-31|  the Congress Party|             HISTORY|'This Asian polit...|       Jeopardy!|       4680| $1000|\n",
      "|2004-12-31|  (Wilt) Chamberlain|ESPN's TOP 10 ALL...|'No. 5: Only cent...|       Jeopardy!|       4680| $1000|\n",
      "|2004-12-31|                  K2|    THE COMPANY LINE|'The Kirschner br...|       Jeopardy!|       4680| $1000|\n",
      "|2004-12-31|         Ethan Allen| EPITAPHS & TRIBUTES|'Revolutionary Wa...|       Jeopardy!|       4680| $1000|\n",
      "|2004-12-31|                 ply|      3-LETTER WORDS|'A single layer o...|       Jeopardy!|       4680| $1000|\n",
      "|2004-12-31|              Horton|DR. SEUSS AT THE ...|'<a href=\"http://...|Double Jeopardy!|       4680|  $400|\n",
      "+----------+--------------------+--------------------+--------------------+----------------+-----------+------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#shows first 30 observations of jeopardy data set\n",
    "jeopardy.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            category|count|\n",
      "+--------------------+-----+\n",
      "|      BEFORE & AFTER|  547|\n",
      "|             SCIENCE|  519|\n",
      "|          LITERATURE|  496|\n",
      "|    AMERICAN HISTORY|  418|\n",
      "|           POTPOURRI|  401|\n",
      "|       WORLD HISTORY|  377|\n",
      "|        WORD ORIGINS|  371|\n",
      "|COLLEGES & UNIVER...|  351|\n",
      "|             HISTORY|  349|\n",
      "|              SPORTS|  342|\n",
      "|         U.S. CITIES|  339|\n",
      "|     WORLD GEOGRAPHY|  338|\n",
      "|     BODIES OF WATER|  327|\n",
      "|             ANIMALS|  324|\n",
      "|      STATE CAPITALS|  314|\n",
      "| BUSINESS & INDUSTRY|  311|\n",
      "|             ISLANDS|  301|\n",
      "|      WORLD CAPITALS|  300|\n",
      "|      U.S. GEOGRAPHY|  299|\n",
      "|            RELIGION|  297|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#shows top 20 categories with highest count of observations, and the counts associated with them\n",
    "j_categoryCount = jeopardy.groupBy(\"category\").count()\n",
    "j_categoryCount.sort(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27995"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the number of categories in the dataset\n",
    "j_categoryCount.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the number of categories in the dataset which have greater than 100 observations\n",
    "j_categoryCount = jeopardy.groupBy(\"category\").count()\n",
    "count100 = j_categoryCount.sort(desc(\"count\")).filter(j_categoryCount[\"count\"] > 100).count()\n",
    "count100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a list of all categories which have a count greater than 100\n",
    "top_categories = list(j_categoryCount.sort(desc(\"count\")).select(\"category\").limit(count100).toPandas().category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------+--------------------+---------+-----------+-----+\n",
      "|  air_date|              answer|      category|            question|    round|show_number|value|\n",
      "+----------+--------------------+--------------+--------------------+---------+-----------+-----+\n",
      "|2004-12-31|          Copernicus|       HISTORY|'For the last 8 y...|Jeopardy!|       4680| $200|\n",
      "|2004-12-31|             the ant|3-LETTER WORDS|'In the title of ...|Jeopardy!|       4680| $200|\n",
      "|2004-12-31|      the Appian Way|       HISTORY|'Built in 312 B.C...|Jeopardy!|       4680| $400|\n",
      "|2004-12-31|             the cud|3-LETTER WORDS|'Cows regurgitate...|Jeopardy!|       4680| $400|\n",
      "|2004-12-31|Ceylon (or Sri La...|       HISTORY|'In 1000 Rajaraja...|Jeopardy!|       4680| $600|\n",
      "+----------+--------------------+--------------+--------------------+---------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Shows 5 observations in our new dataset that only contains categories that have greater than 100 osbervations\n",
    "jeo_f = jeopardy.where(col(\"category\").isin(top_categories))\n",
    "jeo_f.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29252"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeo_f.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for the full jeopardy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_date: string, answer: string, category: string, question: string, round: string, show_number: string, value: string, stripped: string, words: array<string>, filtered: array<string>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stripping punctuation, tokenizing, and stop word removing for the whole dataset\n",
    "jeopardy = jeopardy.withColumn(\"stripped\", f.regexp_replace(f.col(\"question\"), \"[\\!@#$%^&*)(><,';:]\", \"\"))\n",
    "jeopardy.cache()\n",
    "tokenizer = Tokenizer(inputCol = \"stripped\", outputCol = \"words\")\n",
    "tokenized = tokenizer.transform(jeopardy)\n",
    "tokenized.cache()\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "jeopardyStopRemoved = remover.transform(tokenized)\n",
    "jeopardyStopRemoved.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jeopardy.select(\"question\").show(1,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jeopardyStopRemoved.select(\"filtered\").show(1,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_date: string, answer: string, category: string, question: string, round: string, show_number: string, value: string, stripped: string, words: array<string>, filtered: array<string>, stemmed: array<string>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming words in whole dataset\n",
    "jeopardyStemmed = jeopardyStopRemoved.withColumn(\"stemmed\", stemmer_udf(\"filtered\"))\n",
    "jeopardyStemmed.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_date: string, answer: string, category: string, question: string, round: string, show_number: string, value: string, stripped: string, words: array<string>, filtered: array<string>, stemmed: array<string>, rawFeatures: vector, features: vector]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing tf-idf to stemmed words\n",
    "hashingTF1 = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\", numFeatures=50000)\n",
    "featurizedData1 = hashingTF1.transform(jeopardyStemmed)\n",
    "idf1 = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel1 = idf1.fit(featurizedData1)\n",
    "rescaledData1 = idfModel1.transform(featurizedData1)\n",
    "rescaledData1.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means Clustering for the full jeopardy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training, test split\n",
    "training,test = rescaledData1.randomSplit([0.8,0.2], seed = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|        43|  192|\n",
      "|        33|   62|\n",
      "|        31|   11|\n",
      "|        30|  172|\n",
      "|        29|    2|\n",
      "|        28|   83|\n",
      "|        21|    8|\n",
      "|        19|  113|\n",
      "|        17|  384|\n",
      "|        16|    1|\n",
      "|        15|   18|\n",
      "|        11|   36|\n",
      "|        10|    1|\n",
      "|         8|   19|\n",
      "|         5|  307|\n",
      "|         4|  794|\n",
      "|         3|  273|\n",
      "|         2|   40|\n",
      "|         1|  652|\n",
      "|         0|40272|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#kmeans clustering for whole dataset\n",
    "kmeans1 = KMeans(k=50, seed=1)\n",
    "clusters1 = kmeans1.fit(training.select('features'))\n",
    "transformed1 = clusters1.transform(test)\n",
    "transformed1.cache()\n",
    "#This shows the count for each cluster\n",
    "transformed1.groupBy('prediction').count().sort(desc(\"prediction\")).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|category           |question                                                                                                                                                                                                                                                                                                                |\n",
      "+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|\"UP\" SONGS         |'In '80, Diana Ross was \"inside out\" with this #1 hit'                                                                                                                                                                                                                                                                  |\n",
      "|MUSICAL INSTRUMENTS|'\"Instrumental\" title of this, only instrumental no. 1 hit of 1959:'                                                                                                                                                                                                                                                    |\n",
      "|ROCK ‘N ROLL       |'Beatles song about purchasing affection that was 1st to hit #1 in U.S. & Britain at same time'                                                                                                                                                                                                                         |\n",
      "|RELIGION           |'A hit in 1953, this song of faith made No. 3 on the charts when Elvis released in in 1965'                                                                                                                                                                                                                             |\n",
      "|SHOW BIZ BILLYs    |'He's the only filmmaker ever to take home three Academy Awards in 1 night for 1 film, in 1960 for \"The Apartment\"'                                                                                                                                                                                                     |\n",
      "|THE \"I\"'S HAVE IT  |'This John Lennon - Paul McCartney tune was the 1st by the Beatles to reach No. 1 in the U.S.'                                                                                                                                                                                                                          |\n",
      "|RECORD ALBUMS      |'\"You Belong to the City\" was part of this television show's No. 1 album'                                                                                                                                                                                                                                               |\n",
      "|\"BABY\" SONGS       |'(AUDIO DAILY DOUBLE):<br />A No. 12 hit in 1976, it reached No. 1 in 1988 as part of a melody:<br />\"Shadows grow so long before my eyes, and they're moving, across the stage, suddenly, the day turns into night...\"'                                                                                                |\n",
      "|FOOD TRIVIA        |'<a href=\"http://www.j-archive.com/media/1990-01-30_J_30.mp3\">This</a> song, with a food in the title, made No. 2 on the pop charts in 1968:<br /><br /><i>\"Oh, I wake up in the morning, with my hair down in my eyes, and she says Hi!, and I stumble to the breakfast table while the kids are off to school...\"</i>'|\n",
      "|NOVELS             |'Arthur Koestler's criticism of the Soviet Union in which the party leader is referred to only as No. 1'                                                                                                                                                                                                                |\n",
      "|SONGS OF THE '60S  |'Louis Armstrong's only No. 1 hit, it hit the charts for 19 weeks in 1964'                                                                                                                                                                                                                                              |\n",
      "|SONGS OF THE '60S  |'Sonny & Cher's only No. 1 hit, they used to sing it at the close of their TV show'                                                                                                                                                                                                                                     |\n",
      "|SONGS OF THE '60S  |'They had No. 1 hits with Bob Dylan's \"Mr. Tambourine Man\" & Pete Seeger's \"Turn, Turn, Turn\"'                                                                                                                                                                                                                          |\n",
      "|SINGERS            |'\"Get Outta My Dreams, Get Into My Car\" was this singer's third No. 1 single with 8 words in the title'                                                                                                                                                                                                                 |\n",
      "|POTPOURRI          |'This rock star not only had the most No. 1 songs by a solo performer, he also had the most No. 2 hits'                                                                                                                                                                                                                 |\n",
      "|MUSICAL RHYME TIME |'Brian Hyland hit #1 in 1960 singing about this type of \"yellow, polka-dot bikini\"'                                                                                                                                                                                                                                     |\n",
      "|POP MUSIC          |'Their grandfather had a No. 1 record in 1935; their father, No. 1's in 1958 & 1961; and they hit No. 1 in 1990'                                                                                                                                                                                                        |\n",
      "|JAZZ               |'In 1964 vocalist Astrud Gilberto & this tenor saxophonist had a No. 5 pop hit with \"The Girl from Ipanema\"'                                                                                                                                                                                                            |\n",
      "|BESTSELLERS        |'In 1978 this sequel to \"The Winds of War\" was a No. 1 bestseller'                                                                                                                                                                                                                                                      |\n",
      "|POP MUSIC          |'Dionne Warwick's \"That's What Friends Are For\" was knocked out of No. 1 by this first cousin's \"How Will I Know?\"'                                                                                                                                                                                                     |\n",
      "+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed1.filter(transformed1[\"prediction\"] == 5).select(\"category\",\"question\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for the modified jeopardy dataset\n",
    "### The modified jeopardy dataset is where there are only observations where the categories have a count greater than 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_date: string, answer: string, category: string, question: string, round: string, show_number: string, value: string, stripped: string, words: array<string>, filtered: array<string>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stripping punctuation, tokenizing, and stop word removing for the modified dataset\n",
    "jeo_fpunc = jeo_f.withColumn(\"stripped\", f.regexp_replace(f.col(\"question\"), \"[\\!@#$%^&*)(><,';:]\", \"\"))\n",
    "jeo_fpunc.cache()\n",
    "tokenizer = Tokenizer(inputCol = \"stripped\", outputCol = \"words\")\n",
    "tokenized_f = tokenizer.transform(jeo_fpunc)\n",
    "tokenized_f.cache()\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "jeo_fStopRemoved = remover.transform(tokenized_f)\n",
    "jeo_fStopRemoved.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_date: string, answer: string, category: string, question: string, round: string, show_number: string, value: string, stripped: string, words: array<string>, filtered: array<string>, stemmed: array<string>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming words in modified dataset\n",
    "jeo_fStemmed = jeo_fStopRemoved.withColumn(\"stemmed\", stemmer_udf(\"filtered\"))\n",
    "jeo_fStemmed.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training1,test1 = jeo_fStemmed.randomSplit([0.8,0.2], seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_date: string, answer: string, category: string, question: string, round: string, show_number: string, value: string, stripped: string, words: array<string>, filtered: array<string>, stemmed: array<string>, rawFeatures: vector, features: vector]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#peforming tf-idf on modified dataset\n",
    "hashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\", numFeatures=50000)\n",
    "featurizedData = hashingTF.transform(jeo_fStemmed)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = MaxAbsScaler(inputCol=\"sfeatures\", outputCol=\"features\")\n",
    "#scalerModel = scaler.fit(rescaledData)\n",
    "#scaledData = scalerModel.transform(rescaledData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means Clustering for the modified jeopardy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training,test split for modified dataset\n",
    "training,test = rescaledData.randomSplit([0.8,0.2], seed = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost = np.zeros(50)\n",
    "for k in range(2,50):\n",
    "    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n",
    "    model = kmeans.fit(training.sample(False,0.1, seed=42))\n",
    "    cost[k] = model.computeCost(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(1,1, figsize =(8,6))\n",
    "ax.plot(range(2,50),cost[2:50])\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_date: string, answer: string, category: string, question: string, round: string, show_number: string, value: string, stripped: string, words: array<string>, filtered: array<string>, stemmed: array<string>, rawFeatures: vector, features: vector, prediction: int]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kmeans clustering for modified dataset\n",
    "kmeans = KMeans(k=50, seed=1)\n",
    "clusters = kmeans.fit(training.select('features'))\n",
    "transformed = clusters.transform(test)\n",
    "transformed.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|        47|   29|\n",
      "|        46|    2|\n",
      "|        44|   12|\n",
      "|        39|    1|\n",
      "|        36|   11|\n",
      "|        22|  136|\n",
      "|        19|    1|\n",
      "|        18|   45|\n",
      "|        17|    4|\n",
      "|        16|   26|\n",
      "|        13|    1|\n",
      "|        12|   10|\n",
      "|        11|   30|\n",
      "|         8|  161|\n",
      "|         6|   54|\n",
      "|         4|    2|\n",
      "|         3|   68|\n",
      "|         0| 5285|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This shows the count for each cluster\n",
    "transformed.groupBy('prediction').count().sort(desc(\"prediction\")).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------------------------------------------------------------------------------------------+\n",
      "|category            |question                                                                                                    |\n",
      "+--------------------+------------------------------------------------------------------------------------------------------------+\n",
      "|QUOTES              |'\"Reading is to the mind as\" this is \"to the body\"'                                                         |\n",
      "|10-LETTER WORDS     |'Mercy killing'                                                                                             |\n",
      "|WORD ORIGINS        |'From Old French \"manoeuvrer\" meaning \"to work by hand\", which was how this item was put into soil'         |\n",
      "|BIRDS               |'Falcons kill their prey by doing this'                                                                     |\n",
      "|PLAYWRIGHTS         |'His last play, \"What The Butler Saw\", was produced in 1969, 2 years after he was killed'                   |\n",
      "|AUTHORS             |'This author's home where he wrote \"To Have And Have Not\" is now a nat'l landmark in Key West, Fla.'        |\n",
      "|HISTORY             |'Marino Faliero, who was the doge of this, led a plot to kill the nobles & was executed in 1355'            |\n",
      "|FICTIONAL CHARACTERS|'In wooing her, Siegfried was standing in for someone else, & when she found out, she killed him'           |\n",
      "|POTPOURRI           |'These 2 words for conical deposits found in caverns come from the Greek \"stalassein\", meaning \"to drip\"'   |\n",
      "|HODGEPODGE          |'\"To Anacreon In Heaven\" is the original title of the music to which this is set'                           |\n",
      "|MYTHOLOGY           |'Ironically, Jason was killed when a piece of this ship fell & struck him on the head'                      |\n",
      "|WORD ORIGINS        |'This term for a copy or reproduction is from the Latin meaning \"to make similar\"'                          |\n",
      "|5-LETTER WORDS      |'This word for a decorative sticker comes partly from calquer, meaning \"to trace\"'                          |\n",
      "|THE MOVIES          |'The 1967 Sidney Potier film \"To Sir With Love\" was directed by this \"Shogun\" author'                       |\n",
      "|MUSIC               |'An instrumental piece usually for one musician, its name comes from Toccare, Italian for \"to touch\"'       |\n",
      "|POP MUSIC           |'While touring with The Beach Boys, she was cast in a major role in \"To Sir With Love\"'                     |\n",
      "|AUTHORS             |'In 1991 the U. of Alabama awarded this \"To Kill A Mockingbird\" author an honorary Doctor of Letters degree'|\n",
      "|NATURE              |'Eagles usually kill their prey with these body parts'                                                      |\n",
      "|AUTHORS             |'He dedicated his 1888 book \"Plain Tales From The Hills\" \"To the wittiest woman in India\"'                  |\n",
      "|AROUND THE WORLD    |'The Solidarity monument in this Polish port city honors workers killed during the 1970 shipyard strikes'   |\n",
      "+--------------------+------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed.filter(transformed[\"prediction\"] == 3).select(\"category\",\"question\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bisecting K-means for Modified Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training,test split for modified dataset\n",
    "training,test = rescaledData.randomSplit([0.8,0.2], seed = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost = np.zeros(55) \n",
    "for k in range(2,52,10): \n",
    "    bkmeans = BisectingKMeans().setK(k).setSeed(1).setFeaturesCol(\"features\") \n",
    "    model = bkmeans.fit(training.sample(False,0.1, seed=42)) \n",
    "    cost[k] = model.computeCost(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(1,1, figsize =(8,6)) \n",
    "ax.plot(range(2,50),cost[2:50]) \n",
    "ax.set_xlabel('k') \n",
    "ax.set_ylabel('cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkm = BisectingKMeans().setK(50).setSeed(1)\n",
    "model = bkm.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkmpredict = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|        49|    1|\n",
      "|        48|    5|\n",
      "|        47|    4|\n",
      "|        46|   12|\n",
      "|        45|    8|\n",
      "|        44|    9|\n",
      "|        43|   14|\n",
      "|        42|   14|\n",
      "|        41|   57|\n",
      "|        40|   30|\n",
      "|        39|   30|\n",
      "|        38|   32|\n",
      "|        37|  109|\n",
      "|        36|   34|\n",
      "|        35|  116|\n",
      "|        34|   17|\n",
      "|        33|   45|\n",
      "|        32|  159|\n",
      "|        31|  538|\n",
      "|        30|  139|\n",
      "|        29|  131|\n",
      "|        28|   81|\n",
      "|        27|   84|\n",
      "|        26|  136|\n",
      "|        25|  150|\n",
      "|        24|   20|\n",
      "|        23|   39|\n",
      "|        22|  144|\n",
      "|        21|   27|\n",
      "|        20|  497|\n",
      "|        19|  237|\n",
      "|        18|  124|\n",
      "|        17|  156|\n",
      "|        16|  138|\n",
      "|        15|  240|\n",
      "|        14|  300|\n",
      "|        13|  797|\n",
      "|        12|   49|\n",
      "|        11|  147|\n",
      "|        10|   26|\n",
      "|         9|   38|\n",
      "|         8|   48|\n",
      "|         7|   44|\n",
      "|         6|   76|\n",
      "|         5|  259|\n",
      "|         4|   69|\n",
      "|         3|  108|\n",
      "|         2|  188|\n",
      "|         1|   35|\n",
      "|         0|  117|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bkmpredict.groupBy('prediction').count().sort(desc(\"prediction\")).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------------------------------------------------------------------------------------+\n",
      "|category       |question                                                                                          |\n",
      "+---------------+--------------------------------------------------------------------------------------------------+\n",
      "|LAKES & RIVERS |'Scottish word for lake'                                                                          |\n",
      "|LAKES & RIVERS |'The end of a river that empties into a lake or ocean'                                            |\n",
      "|LAKES & RIVERS |'This lake in the Banff National Park is the most visited place in the Canadian Rockies'          |\n",
      "|BODIES OF WATER|'Once part of the Gulf of California, it's now the largest natural lake entirely within the state'|\n",
      "|U.S. GEOGRAPHY |'This lake was created when Hoover Dam was built on the Colorado River'                           |\n",
      "|ISLANDS        |'Over 500 bison live in the Bison Refuge on Antelope Island in this Utah lake'                    |\n",
      "|LAKES & RIVERS |'Seneca is the largest of these lakes in west-central New York'                                   |\n",
      "|U.S. GEOGRAPHY |'At about 440 square miles, Red Lake is the largest of this state's \"10,000 Lakes\"'               |\n",
      "|U.S. GEOGRAPHY |'Antelope Island in this Utah lake is used as a refuge for bison'                                 |\n",
      "|WORLD GEOGRAPHY|'This narrow lake, part of Scotland's Caledonian Canal, is home to a famous monster'              |\n",
      "|LAKES & RIVERS |'This state's largest lake, Lake Hapatcong, lies about 25 miles west of Passaic'                  |\n",
      "|ISLANDS        |'Wisconsin's Apostle Islands lie in this Great Lake'                                              |\n",
      "|BODIES OF WATER|'One of the world's largest artificial lakes is Lake Nasser, a reservoir on this river'           |\n",
      "|BODIES OF WATER|'Lake Neuchatel is the largest lake entirely within this European country's boundaries'           |\n",
      "|MOUNTAINS      |'Lake Placid lies in this mountain chain in northeastern New York'                                |\n",
      "|WORLD GEOGRAPHY|'This country's Lake Balaton, just southwest of Budapest, is central Europe's largest lake'       |\n",
      "|LAKES & RIVERS |'A short channel connects this large lake with the Gulf of Venezuela'                             |\n",
      "|LAKES & RIVERS |'This \"lifeless\" lake is known in Arabic as the Sea of Lot'                                       |\n",
      "|BODIES OF WATER|'Windemere is the largest lake in this country's Lake District'                                   |\n",
      "|LAKES & RIVERS |'This largest of the Great Lakes is also the highest above sea level at 600 feet'                 |\n",
      "+---------------+--------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bkmpredict.filter(bkmpredict[\"prediction\"] == 1).select(\"category\",\"question\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification for Modified Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|label|category         |\n",
      "+-----+-----------------+\n",
      "|8.0  |HISTORY          |\n",
      "|42.0 |3-LETTER WORDS   |\n",
      "|8.0  |HISTORY          |\n",
      "|42.0 |3-LETTER WORDS   |\n",
      "|8.0  |HISTORY          |\n",
      "|42.0 |3-LETTER WORDS   |\n",
      "|8.0  |HISTORY          |\n",
      "|42.0 |3-LETTER WORDS   |\n",
      "|8.0  |HISTORY          |\n",
      "|42.0 |3-LETTER WORDS   |\n",
      "|81.0 |IN THE DICTIONARY|\n",
      "|81.0 |IN THE DICTIONARY|\n",
      "|81.0 |IN THE DICTIONARY|\n",
      "|81.0 |IN THE DICTIONARY|\n",
      "|81.0 |IN THE DICTIONARY|\n",
      "|77.0 |TRAVEL & TOURISM |\n",
      "|77.0 |TRAVEL & TOURISM |\n",
      "|77.0 |TRAVEL & TOURISM |\n",
      "|77.0 |TRAVEL & TOURISM |\n",
      "|77.0 |TRAVEL & TOURISM |\n",
      "+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#making numerical labels for each category\n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"label\")\n",
    "indexed = indexer.fit(rescaledData).transform(rescaledData)\n",
    "indexed.select(\"label\",\"category\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting to training and test for classification\n",
    "training,test = indexed.randomSplit([0.8,0.2], seed = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_date: string, answer: string, category: string, question: string, round: string, show_number: string, value: string, stripped: string, words: array<string>, filtered: array<string>, stemmed: array<string>, rawFeatures: vector, features: vector, label: double, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\", featuresCol = \"features\", labelCol = \"label\")\n",
    "model = nb.fit(training)\n",
    "predictions = model.transform(test)\n",
    "predictions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.2689690370874447\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for Naive Bayes Classification for Modified Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\")\n",
    "idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\")\n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"label\")\n",
    "nb = NaiveBayes(modelType=\"multinomial\", featuresCol = idf.getOutputCol(), labelCol = \"label\")\n",
    "pipeline = Pipeline(stages=[hashingTF,idf,indexer,nb])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [1000,10000,50000]) \\\n",
    "    .addGrid(nb.smoothing, [1.0]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=5)\n",
    "cvModel = crossval.fit(training1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction = cvModel.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
