{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with loading all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "#from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *       # for datatype conversion\n",
    "from pyspark.sql.functions import *   # for col() function\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "import re\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.ml.feature import MaxAbsScaler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlCtx = SQLContext(sc)\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Jeopardy Calculation\") \\\n",
    "    .config(\"spark.executor.memory\", '2g') \\\n",
    "    .config('spark.executor.cores', '1') \\\n",
    "    .config('spark.cores.max', '1') \\\n",
    "    .config(\"spark.driver.memory\",'1g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "def stem(in_vec):\n",
    "    out_vec = []\n",
    "    for t in in_vec:\n",
    "        t_stem = stemmer.stem(t)\n",
    "        out_vec.append(t_stem)       \n",
    "    return out_vec\n",
    "from pyspark.sql.types import *\n",
    "stemmer_udf = udf(lambda x: stem(x), ArrayType(StringType()))\n",
    "\n",
    "#reading in the jeopardy data set\n",
    "jeopardy = spark.read.json(\"data/JEOPARDY_QUESTIONS1.json\")\n",
    "\n",
    "#This is the number of categories in the dataset which have greater than 100 observations\n",
    "j_categoryCount = jeopardy.groupBy(\"category\").count()\n",
    "count100 = j_categoryCount.sort(desc(\"count\")).filter(j_categoryCount[\"count\"] > 100).count()\n",
    "count100\n",
    "\n",
    "#This is a list of all categories which have a count greater than 100\n",
    "top_categories = list(j_categoryCount.sort(desc(\"count\")).select(\"category\").limit(50).toPandas().category)\n",
    "\n",
    "jeo_f = jeopardy.where(col(\"category\").isin(top_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15012"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeo_f.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_date: string, answer: string, category: string, question: string, round: string, show_number: string, value: string, stripped: string, words: array<string>, filtered: array<string>, stemmed: array<string>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stripping punctuation, tokenizing, and stop word removing for the modified dataset\n",
    "jeo_fpunc = jeo_f.withColumn(\"stripped\", f.regexp_replace(f.col(\"question\"), \"[\\!@#$%^&*)(><,';:]\", \"\"))\n",
    "jeo_fpunc.cache()\n",
    "tokenizer = Tokenizer(inputCol = \"stripped\", outputCol = \"words\")\n",
    "tokenized_f = tokenizer.transform(jeo_fpunc)\n",
    "tokenized_f.cache()\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "jeo_fStopRemoved = remover.transform(tokenized_f)\n",
    "jeo_fStopRemoved.cache()\n",
    "\n",
    "#stemming words in modified dataset\n",
    "jeo_fStemmed = jeo_fStopRemoved.withColumn(\"stemmed\", stemmer_udf(\"filtered\"))\n",
    "jeo_fStemmed.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_date: string, answer: string, category: string, question: string, round: string, show_number: string, value: string, stripped: string, words: array<string>, filtered: array<string>, stemmed: array<string>, rawFeatures: vector, features: vector]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#peforming tf-idf on modified dataset\n",
    "hashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\", numFeatures=50000)\n",
    "featurizedData = hashingTF.transform(jeo_fStemmed)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------+\n",
      "|label|category               |\n",
      "+-----+-----------------------+\n",
      "|6.0  |WORD ORIGINS           |\n",
      "|5.0  |WORLD HISTORY          |\n",
      "|37.0 |SCIENCE & NATURE       |\n",
      "|27.0 |RHYME TIME             |\n",
      "|4.0  |POTPOURRI              |\n",
      "|48.0 |POETS & POETRY         |\n",
      "|4.0  |POTPOURRI              |\n",
      "|18.0 |U.S. GEOGRAPHY         |\n",
      "|15.0 |BUSINESS & INDUSTRY    |\n",
      "|34.0 |U.S. HISTORY           |\n",
      "|3.0  |AMERICAN HISTORY       |\n",
      "|29.0 |ART & ARTISTS          |\n",
      "|32.0 |ART                    |\n",
      "|41.0 |HOLIDAYS & OBSERVANCES |\n",
      "|28.0 |TRANSPORTATION         |\n",
      "|10.0 |U.S. CITIES            |\n",
      "|22.0 |LANGUAGES              |\n",
      "|23.0 |BALLET                 |\n",
      "|23.0 |BALLET                 |\n",
      "|27.0 |RHYME TIME             |\n",
      "|48.0 |POETS & POETRY         |\n",
      "|34.0 |U.S. HISTORY           |\n",
      "|7.0  |COLLEGES & UNIVERSITIES|\n",
      "|32.0 |ART                    |\n",
      "|31.0 |THE BIBLE              |\n",
      "|16.0 |ISLANDS                |\n",
      "|8.0  |HISTORY                |\n",
      "|46.0 |AUTHORS                |\n",
      "|33.0 |BOOKS & AUTHORS        |\n",
      "|32.0 |ART                    |\n",
      "|34.0 |U.S. HISTORY           |\n",
      "|9.0  |SPORTS                 |\n",
      "|48.0 |POETS & POETRY         |\n",
      "|5.0  |WORLD HISTORY          |\n",
      "|30.0 |STUPID ANSWERS         |\n",
      "|4.0  |POTPOURRI              |\n",
      "|4.0  |POTPOURRI              |\n",
      "|30.0 |STUPID ANSWERS         |\n",
      "|35.0 |FOOD                   |\n",
      "|23.0 |BALLET                 |\n",
      "|0.0  |BEFORE & AFTER         |\n",
      "|36.0 |MUSEUMS                |\n",
      "|32.0 |ART                    |\n",
      "|1.0  |SCIENCE                |\n",
      "|12.0 |BODIES OF WATER        |\n",
      "|14.0 |STATE CAPITALS         |\n",
      "|17.0 |WORLD CAPITALS         |\n",
      "|6.0  |WORD ORIGINS           |\n",
      "|48.0 |POETS & POETRY         |\n",
      "|1.0  |SCIENCE                |\n",
      "+-----+-----------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#making numerical labels for each category\n",
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"label\")\n",
    "indexed = indexer.fit(rescaledData).transform(rescaledData)\n",
    "indexed.distinct().select(\"label\",\"category\").show(50,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training,test = indexed.randomSplit([0.8,0.2], seed = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air_date',\n",
       " 'answer',\n",
       " 'category',\n",
       " 'question',\n",
       " 'round',\n",
       " 'show_number',\n",
       " 'value',\n",
       " 'stripped',\n",
       " 'words',\n",
       " 'filtered',\n",
       " 'stemmed',\n",
       " 'rawFeatures',\n",
       " 'features',\n",
       " 'label']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11984"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3028"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "| 49.0|   51|\n",
      "| 48.0|   53|\n",
      "| 47.0|   40|\n",
      "| 46.0|   43|\n",
      "| 45.0|   49|\n",
      "| 44.0|   48|\n",
      "| 43.0|   42|\n",
      "| 42.0|   45|\n",
      "| 41.0|   47|\n",
      "| 40.0|   56|\n",
      "| 39.0|   47|\n",
      "| 38.0|   53|\n",
      "| 37.0|   60|\n",
      "| 36.0|   39|\n",
      "| 35.0|   51|\n",
      "| 34.0|   67|\n",
      "| 33.0|   65|\n",
      "| 32.0|   62|\n",
      "| 31.0|   47|\n",
      "| 30.0|   62|\n",
      "| 29.0|   47|\n",
      "| 28.0|   59|\n",
      "| 27.0|   55|\n",
      "| 26.0|   57|\n",
      "| 25.0|   53|\n",
      "| 24.0|   58|\n",
      "| 23.0|   59|\n",
      "| 22.0|   63|\n",
      "| 21.0|   61|\n",
      "| 20.0|   53|\n",
      "+-----+-----+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testgroup = test.groupby(\"label\").count()\n",
    "testgroup.sort(desc(\"label\")).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_date: string, answer: string, category: string, question: string, round: string, show_number: string, value: string, stripped: string, words: array<string>, filtered: array<string>, stemmed: array<string>, rawFeatures: vector, features: vector, label: double, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10, regParam=0.005, elasticNetParam=0.8, family=\"multinomial\")\n",
    "lrModel = lr.fit(training)\n",
    "predictions = lrModel.transform(test)\n",
    "predictions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|category            |label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|THE BIBLE           |31.0 |44.0      |\n",
      "|TRANSPORTATION      |28.0 |28.0      |\n",
      "|OPERA               |20.0 |0.0       |\n",
      "|TRANSPORTATION      |28.0 |0.0       |\n",
      "|U.S. HISTORY        |34.0 |3.0       |\n",
      "|ANIMALS             |13.0 |13.0      |\n",
      "|ANIMALS             |13.0 |2.0       |\n",
      "|GEOGRAPHY           |40.0 |41.0      |\n",
      "|GEOGRAPHY           |40.0 |40.0      |\n",
      "|STATE CAPITALS      |14.0 |17.0      |\n",
      "|GEOGRAPHY           |40.0 |12.0      |\n",
      "|BUSINESS & INDUSTRY |15.0 |15.0      |\n",
      "|STATE CAPITALS      |14.0 |0.0       |\n",
      "|TRANSPORTATION      |28.0 |28.0      |\n",
      "|SHAKESPEARE         |21.0 |21.0      |\n",
      "|SHAKESPEARE         |21.0 |42.0      |\n",
      "|SCIENCE             |1.0  |13.0      |\n",
      "|LITERATURE          |2.0  |49.0      |\n",
      "|LITERATURE          |2.0  |44.0      |\n",
      "|SPORTS              |9.0  |47.0      |\n",
      "|LITERATURE          |2.0  |25.0      |\n",
      "|U.S. HISTORY        |34.0 |49.0      |\n",
      "|SHAKESPEARE         |21.0 |0.0       |\n",
      "|SHAKESPEARE         |21.0 |13.0      |\n",
      "|WORLD CAPITALS      |17.0 |17.0      |\n",
      "|SPORTS              |9.0  |9.0       |\n",
      "|SPORTS              |9.0  |9.0       |\n",
      "|SPORTS              |9.0  |9.0       |\n",
      "|U.S. GEOGRAPHY      |18.0 |10.0      |\n",
      "|TELEVISION          |24.0 |38.0      |\n",
      "|GEOGRAPHY           |40.0 |16.0      |\n",
      "|SCIENCE             |1.0  |0.0       |\n",
      "|WORLD GEOGRAPHY     |11.0 |8.0       |\n",
      "|WORLD GEOGRAPHY     |11.0 |28.0      |\n",
      "|FOOD                |35.0 |18.0      |\n",
      "|RELIGION            |19.0 |19.0      |\n",
      "|U.S. HISTORY        |34.0 |0.0       |\n",
      "|SPORTS              |9.0  |1.0       |\n",
      "|U.S. CITIES         |10.0 |10.0      |\n",
      "|U.S. CITIES         |10.0 |40.0      |\n",
      "|HISTORY             |8.0  |7.0       |\n",
      "|HISTORY             |8.0  |5.0       |\n",
      "|THE BIBLE           |31.0 |31.0      |\n",
      "|SCIENCE             |1.0  |0.0       |\n",
      "|WORLD HISTORY       |5.0  |5.0       |\n",
      "|WORLD HISTORY       |5.0  |28.0      |\n",
      "|SCIENCE             |1.0  |1.0       |\n",
      "|GEOGRAPHY           |40.0 |18.0      |\n",
      "|SCIENCE             |1.0  |35.0      |\n",
      "|LITERATURE          |2.0  |22.0      |\n",
      "|WORLD CAPITALS      |17.0 |14.0      |\n",
      "|FOOD                |35.0 |5.0       |\n",
      "|AMERICAN HISTORY    |3.0  |3.0       |\n",
      "|ANIMALS             |13.0 |13.0      |\n",
      "|TELEVISION          |24.0 |26.0      |\n",
      "|U.S. CITIES         |10.0 |5.0       |\n",
      "|SCIENCE             |1.0  |24.0      |\n",
      "|FOOD                |35.0 |4.0       |\n",
      "|FOOD                |35.0 |6.0       |\n",
      "|ISLANDS             |16.0 |6.0       |\n",
      "|THE BIBLE           |31.0 |5.0       |\n",
      "|THE BIBLE           |31.0 |31.0      |\n",
      "|SCIENCE             |1.0  |1.0       |\n",
      "|SCIENCE             |1.0  |13.0      |\n",
      "|ART                 |32.0 |29.0      |\n",
      "|ART                 |32.0 |7.0       |\n",
      "|ART                 |32.0 |35.0      |\n",
      "|SHAKESPEARE         |21.0 |5.0       |\n",
      "|CLASSICAL MUSIC     |45.0 |37.0      |\n",
      "|U.S. HISTORY        |34.0 |11.0      |\n",
      "|RELIGION            |19.0 |17.0      |\n",
      "|U.S. HISTORY        |34.0 |43.0      |\n",
      "|RELIGION            |19.0 |19.0      |\n",
      "|WORD ORIGINS        |6.0  |6.0       |\n",
      "|SPORTS              |9.0  |9.0       |\n",
      "|SPORTS              |9.0  |0.0       |\n",
      "|U.S. HISTORY        |34.0 |3.0       |\n",
      "|TELEVISION          |24.0 |3.0       |\n",
      "|GEOGRAPHY           |40.0 |41.0      |\n",
      "|WORD ORIGINS        |6.0  |4.0       |\n",
      "|WORD ORIGINS        |6.0  |16.0      |\n",
      "|WORD ORIGINS        |6.0  |34.0      |\n",
      "|HISTORY             |8.0  |47.0      |\n",
      "|RELIGION            |19.0 |19.0      |\n",
      "|THE BIBLE           |31.0 |0.0       |\n",
      "|THE BIBLE           |31.0 |31.0      |\n",
      "|THE BIBLE           |31.0 |31.0      |\n",
      "|THE BIBLE           |31.0 |6.0       |\n",
      "|RELIGION            |19.0 |19.0      |\n",
      "|RELIGION            |19.0 |19.0      |\n",
      "|SCIENCE             |1.0  |37.0      |\n",
      "|BUSINESS & INDUSTRY |15.0 |15.0      |\n",
      "|FICTIONAL CHARACTERS|25.0 |25.0      |\n",
      "|WORLD HISTORY       |5.0  |0.0       |\n",
      "|U.S. CITIES         |10.0 |14.0      |\n",
      "|BALLET              |23.0 |23.0      |\n",
      "|U.S. HISTORY        |34.0 |3.0       |\n",
      "|TRANSPORTATION      |28.0 |1.0       |\n",
      "|STATE CAPITALS      |14.0 |17.0      |\n",
      "|LANGUAGES           |22.0 |22.0      |\n",
      "+--------------------+-----+----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"category\", \"label\",\"prediction\").show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+----------+\n",
      "|           category|label|prediction|\n",
      "+-------------------+-----+----------+\n",
      "|     TRANSPORTATION| 28.0|      28.0|\n",
      "|            ANIMALS| 13.0|      13.0|\n",
      "|          GEOGRAPHY| 40.0|      40.0|\n",
      "|BUSINESS & INDUSTRY| 15.0|      15.0|\n",
      "|     TRANSPORTATION| 28.0|      28.0|\n",
      "|        SHAKESPEARE| 21.0|      21.0|\n",
      "|     WORLD CAPITALS| 17.0|      17.0|\n",
      "|             SPORTS|  9.0|       9.0|\n",
      "|             SPORTS|  9.0|       9.0|\n",
      "|             SPORTS|  9.0|       9.0|\n",
      "|           RELIGION| 19.0|      19.0|\n",
      "|        U.S. CITIES| 10.0|      10.0|\n",
      "|          THE BIBLE| 31.0|      31.0|\n",
      "|      WORLD HISTORY|  5.0|       5.0|\n",
      "|            SCIENCE|  1.0|       1.0|\n",
      "|   AMERICAN HISTORY|  3.0|       3.0|\n",
      "|            ANIMALS| 13.0|      13.0|\n",
      "|          THE BIBLE| 31.0|      31.0|\n",
      "|            SCIENCE|  1.0|       1.0|\n",
      "|           RELIGION| 19.0|      19.0|\n",
      "+-------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.filter(predictions[\"label\"] == predictions[\"prediction\"]).select(\"category\",\"label\",\"prediction\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.39531043593130777\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
