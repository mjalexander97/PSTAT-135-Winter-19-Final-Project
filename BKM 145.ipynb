{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *       # for datatype conversion\n",
    "from pyspark.sql.functions import *   # for col() function\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "import re\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.sql.types import *       # for datatype conversion\n",
    "from pyspark.sql.functions import *   # for col() function\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import pandas as pd\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlCtx = SQLContext(sc)\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Jeopardy Calculation\") \\\n",
    "    .config(\"spark.executor.memory\", '2g') \\\n",
    "    .config('spark.executor.cores', '1') \\\n",
    "    .config('spark.cores.max', '1') \\\n",
    "    .config(\"spark.driver.memory\",'1g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "jeopardy = spark.read.json('data/JEOPARDY_QUESTIONS1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the number of categories in the dataset which have greater than 50 observations\n",
    "j_categoryCount = jeopardy.groupBy(\"category\").count()\n",
    "count100 = j_categoryCount.sort(desc(\"count\")).filter(j_categoryCount[\"count\"] > 100).count()\n",
    "count100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BEFORE & AFTER',\n",
       " 'SCIENCE',\n",
       " 'LITERATURE',\n",
       " 'AMERICAN HISTORY',\n",
       " 'POTPOURRI',\n",
       " 'WORLD HISTORY',\n",
       " 'WORD ORIGINS',\n",
       " 'COLLEGES & UNIVERSITIES',\n",
       " 'HISTORY',\n",
       " 'SPORTS',\n",
       " 'U.S. CITIES',\n",
       " 'WORLD GEOGRAPHY',\n",
       " 'BODIES OF WATER',\n",
       " 'ANIMALS',\n",
       " 'STATE CAPITALS',\n",
       " 'BUSINESS & INDUSTRY',\n",
       " 'ISLANDS',\n",
       " 'WORLD CAPITALS',\n",
       " 'U.S. GEOGRAPHY',\n",
       " 'RELIGION',\n",
       " 'OPERA',\n",
       " 'SHAKESPEARE',\n",
       " 'LANGUAGES',\n",
       " 'BALLET',\n",
       " 'TELEVISION',\n",
       " 'FICTIONAL CHARACTERS',\n",
       " 'RHYME TIME',\n",
       " 'PEOPLE',\n",
       " 'TRANSPORTATION',\n",
       " 'ART & ARTISTS',\n",
       " 'STUPID ANSWERS',\n",
       " 'THE BIBLE',\n",
       " 'ART',\n",
       " 'BOOKS & AUTHORS',\n",
       " 'U.S. HISTORY',\n",
       " 'FOOD',\n",
       " 'MUSEUMS',\n",
       " 'SCIENCE & NATURE',\n",
       " 'AMERICANA',\n",
       " 'COMMON BONDS',\n",
       " 'GEOGRAPHY',\n",
       " 'HOLIDAYS & OBSERVANCES',\n",
       " '3-LETTER WORDS',\n",
       " 'ANNUAL EVENTS',\n",
       " 'AMERICAN LITERATURE',\n",
       " 'CLASSICAL MUSIC',\n",
       " 'AUTHORS',\n",
       " 'POP MUSIC',\n",
       " 'POETS & POETRY',\n",
       " 'QUOTATIONS',\n",
       " 'HODGEPODGE',\n",
       " 'MYTHOLOGY',\n",
       " 'NONFICTION',\n",
       " 'THE MOVIES',\n",
       " 'WORLD CITIES',\n",
       " 'MUSICAL INSTRUMENTS',\n",
       " 'AROUND THE WORLD',\n",
       " 'THE CIVIL WAR',\n",
       " 'MUSIC',\n",
       " 'U.S. PRESIDENTS',\n",
       " 'COMPOSERS',\n",
       " 'ASTRONOMY',\n",
       " 'FOOD & DRINK',\n",
       " '4-LETTER WORDS',\n",
       " 'HISTORIC NAMES',\n",
       " 'BIOLOGY',\n",
       " 'MOUNTAINS',\n",
       " 'POTENT POTABLES',\n",
       " 'HOMOPHONES',\n",
       " 'EUROPEAN HISTORY',\n",
       " 'MEDICINE',\n",
       " 'EXPLORERS',\n",
       " 'ORGANIZATIONS',\n",
       " 'SCIENTISTS',\n",
       " 'ARCHITECTURE',\n",
       " 'WEIGHTS & MEASURES',\n",
       " 'FIRST LADIES',\n",
       " 'TRAVEL & TOURISM',\n",
       " 'FRUITS & VEGETABLES',\n",
       " 'THE BODY HUMAN',\n",
       " 'MAGAZINES',\n",
       " 'IN THE DICTIONARY',\n",
       " 'FAMOUS AMERICANS',\n",
       " 'AWARDS',\n",
       " 'ZOOLOGY',\n",
       " 'NATURE',\n",
       " 'FOREIGN WORDS & PHRASES',\n",
       " 'VOCABULARY',\n",
       " 'FASHION',\n",
       " 'THEATRE',\n",
       " '5-LETTER WORDS',\n",
       " 'CHEMISTRY',\n",
       " '19th CENTURY AMERICA',\n",
       " 'PHYSICS',\n",
       " 'GOVERNMENT & POLITICS',\n",
       " 'WORLD LEADERS',\n",
       " 'U.S. STATES',\n",
       " 'ABBREV.',\n",
       " 'NOTABLE NAMES',\n",
       " 'ARTISTS',\n",
       " 'GENERAL SCIENCE',\n",
       " 'THE AMERICAN REVOLUTION',\n",
       " '10-LETTER WORDS',\n",
       " 'ANATOMY',\n",
       " 'FAMOUS NAMES',\n",
       " 'ACTORS & ACTRESSES',\n",
       " 'LAKES & RIVERS',\n",
       " 'COUNTRIES OF THE WORLD',\n",
       " 'BIRDS',\n",
       " 'ODDS & ENDS',\n",
       " 'POP CULTURE',\n",
       " 'PEOPLE IN HISTORY',\n",
       " 'HAIL TO THE CHIEF',\n",
       " 'FAMILIAR PHRASES',\n",
       " 'POETRY',\n",
       " 'SIGNS & SYMBOLS',\n",
       " 'MAMMALS',\n",
       " 'HEALTH & MEDICINE',\n",
       " 'U.S.A.',\n",
       " 'POLITICIANS',\n",
       " 'BOTANY',\n",
       " 'QUOTES',\n",
       " 'INVENTORS',\n",
       " 'CLASSICAL COMPOSERS',\n",
       " 'LETTER PERFECT',\n",
       " 'SCULPTURE',\n",
       " 'HISTORIC AMERICANS',\n",
       " 'SINGERS',\n",
       " 'THE OLD TESTAMENT',\n",
       " 'ROYALTY',\n",
       " 'MUSICAL THEATRE',\n",
       " 'DOUBLE TALK',\n",
       " 'COLORS',\n",
       " 'WORLD LITERATURE',\n",
       " 'BODY LANGUAGE',\n",
       " 'ARCHAEOLOGY',\n",
       " 'EUROPE',\n",
       " 'THE ELEMENTS',\n",
       " 'TECHNOLOGY',\n",
       " 'MIDDLE NAMES',\n",
       " 'PLAYWRIGHTS',\n",
       " 'THE OSCARS',\n",
       " 'FAMOUS WOMEN',\n",
       " 'ANCIENT HISTORY',\n",
       " 'LIBRARIES']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is a list of all categories which have a count greater than 50\n",
    "top_categories = list(j_categoryCount.sort(desc(\"count\")).select(\"category\").limit(count100).toPandas().category)\n",
    "top_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeo_f = jeopardy.where(col(\"category\").isin(top_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_date: string, answer: string, category: string, question: string, round: string, show_number: string, value: string, stripped: string, words: array<string>, filtered: array<string>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stripping punctuation, tokenizing, and stop word removing for the modified dataset\n",
    "jeo_fpunc = jeo_f.withColumn(\"stripped\", f.regexp_replace(f.col(\"question\"), \"[\\!@#$%^&*)(><,';:]\", \"\"))\n",
    "jeo_fpunc.cache()\n",
    "tokenizer = Tokenizer(inputCol = \"stripped\", outputCol = \"words\")\n",
    "tokenized_f = tokenizer.transform(jeo_fpunc)\n",
    "tokenized_f.cache()\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "jeo_fStopRemoved = remover.transform(tokenized_f)\n",
    "jeo_fStopRemoved.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem(in_vec):\n",
    "    out_vec = []\n",
    "    for t in in_vec:\n",
    "        t_stem = stemmer.stem(t)\n",
    "        out_vec.append(t_stem)       \n",
    "    return out_vec\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "stemmer_udf = udf(lambda x: stem(x), ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_date: string, answer: string, category: string, question: string, round: string, show_number: string, value: string, stripped: string, words: array<string>, filtered: array<string>, stemmed: array<string>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming words in modified dataset\n",
    "jeo_fStemmed = jeo_fStopRemoved.withColumn(\"stemmed\", stemmer_udf(\"filtered\"))\n",
    "jeo_fStemmed.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error',)).History will not be written to the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[air_date: string, answer: string, category: string, question: string, round: string, show_number: string, value: string, stripped: string, words: array<string>, filtered: array<string>, stemmed: array<string>, rawFeatures: vector, features: vector]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\", numFeatures=50000)\n",
    "featurizedData = hashingTF.transform(jeo_fStemmed)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training,test = rescaledData.randomSplit([0.8,0.2], seed = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import BisectingKMeans, BisectingKMeansModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkm = BisectingKMeans().setK(145).setSeed(1)\n",
    "model = bkm.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkmpredict = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       144|    1|\n",
      "|       138|    1|\n",
      "|       137|    4|\n",
      "|       133|    4|\n",
      "|       130|    5|\n",
      "|       129|    7|\n",
      "|       127|    6|\n",
      "|       125|    2|\n",
      "|       122|    1|\n",
      "|       121|    8|\n",
      "|       120|    2|\n",
      "|       119|    1|\n",
      "|       118|    6|\n",
      "|       117|    5|\n",
      "|       115|    5|\n",
      "|       114|    4|\n",
      "|       113|    5|\n",
      "|       112|    1|\n",
      "|       111|   10|\n",
      "|       110|   13|\n",
      "|       109|   33|\n",
      "|       108|    4|\n",
      "|       107|    8|\n",
      "|       106|    6|\n",
      "|       105|   12|\n",
      "|       104|    3|\n",
      "|       103|   16|\n",
      "|       102|    4|\n",
      "|       101|    7|\n",
      "|       100|    9|\n",
      "|        99|   35|\n",
      "|        98|   28|\n",
      "|        97|   69|\n",
      "|        96|   13|\n",
      "|        95|   18|\n",
      "|        94|   42|\n",
      "|        93|   77|\n",
      "|        92|    2|\n",
      "|        91|    3|\n",
      "|        90|    8|\n",
      "|        89|   49|\n",
      "|        88|   35|\n",
      "|        87|   98|\n",
      "|        86|   50|\n",
      "|        85|   38|\n",
      "|        84|   57|\n",
      "|        83|  111|\n",
      "|        82|   56|\n",
      "|        81|  252|\n",
      "|        80|   61|\n",
      "|        79|   36|\n",
      "|        78|   84|\n",
      "|        77|   89|\n",
      "|        76|   32|\n",
      "|        75|   55|\n",
      "|        74|   17|\n",
      "|        73|   61|\n",
      "|        72|   66|\n",
      "|        71|   76|\n",
      "|        70|   60|\n",
      "|        69|   84|\n",
      "|        68|    7|\n",
      "|        67|   16|\n",
      "|        66|    5|\n",
      "|        65|   31|\n",
      "|        64|   40|\n",
      "|        63|   88|\n",
      "|        62|   34|\n",
      "|        61|    9|\n",
      "|        60|  108|\n",
      "|        59|   36|\n",
      "|        58|   45|\n",
      "|        57|  159|\n",
      "|        56|   37|\n",
      "|        55|   67|\n",
      "|        54|   87|\n",
      "|        53|  195|\n",
      "|        52|   25|\n",
      "|        51|   36|\n",
      "|        50|   58|\n",
      "|        49|   52|\n",
      "|        48|   54|\n",
      "|        47|   55|\n",
      "|        46|   49|\n",
      "|        45|   24|\n",
      "|        44|  106|\n",
      "|        43|  107|\n",
      "|        42|   92|\n",
      "|        41|   71|\n",
      "|        40|   72|\n",
      "|        39|   76|\n",
      "|        38|   62|\n",
      "|        37|   29|\n",
      "|        36|   56|\n",
      "|        35|  368|\n",
      "|        34|  363|\n",
      "|        33|   25|\n",
      "|        32|   29|\n",
      "|        31|   50|\n",
      "|        30|   92|\n",
      "|        29|    1|\n",
      "|        28|    2|\n",
      "|        27|    1|\n",
      "|        26|   22|\n",
      "|        25|   12|\n",
      "|        24|    5|\n",
      "|        23|    5|\n",
      "|        22|   16|\n",
      "|        21|   13|\n",
      "|        20|    8|\n",
      "|        19|    2|\n",
      "|        18|   25|\n",
      "|        17|   15|\n",
      "|        16|   22|\n",
      "|        15|   19|\n",
      "|        14|   64|\n",
      "|        13|   39|\n",
      "|        12|   60|\n",
      "|        11|   64|\n",
      "|        10|  123|\n",
      "|         9|   30|\n",
      "|         8|   12|\n",
      "|         7|   42|\n",
      "|         6|   87|\n",
      "|         5|   55|\n",
      "|         4|  112|\n",
      "|         3|   20|\n",
      "|         2|   82|\n",
      "|         1|    9|\n",
      "|         0|   41|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bkmpredict.groupBy('prediction').count().sort(desc('prediction')).show(145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|category           |question                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|RHYME TIME         |'(<a href=\"http://www.j-archive.com/media/2004-09-14_DJ_13.wmv\">Sofia of the Clue Crew wears inappropriate attire that is too revealing.</a>)  Here's some advice--don't wear a St. Patty's Day shirt when working with this'                                                                                                                                             |\n",
      "|MUSIC              |'(<a href=\"http://www.j-archive.com/media/2005-03-15_DJ_16.wmv\">Cheryl of the Clue Crew blows into a saxophone.</a>)  From the French for \"mouth\", it's the way you form your lips & teeth around a horn's mouthpiece'                                                                                                                                                    |\n",
      "|CLASSICAL COMPOSERS|'(<a href=\"http://www.j-archive.com/media/2005-12-21_DJ_05.jpg\" target=\"_blank\">Jon of the Clue Crew walks up the nave of the Marienkirche in Lubeck, Germany.</a>)  In 1705 this 20-year-old composer walked 200 miles to hear Dietrich Buxtehude play organ at Lubeck's <a href=\"http://www.j-archive.com/media/2005-12-21_DJ_05a.jpg\" target=\"_blank\">Marienkirche</a>'|\n",
      "|THE ELEMENTS       |'(<a href=\"http://www.j-archive.com/media/2006-02-22_DJ_08.jpg\" target=\"_blank\">Jon of the Clue Crew delivers the clue from a kitchen.</a>)  The ancients & the alchemists knew about the flammability of this element; today, it's the main fuel that makes matches strike'                                                                                              |\n",
      "|SCIENCE            |'(<a href=\"http://www.j-archive.com/media/2007-10-08_DJ_22.jpg\" target=\"_blank\">Jon of the Clue Crew puts a lid on it--literally.</a>) The candle in the small jar will <a href=\"http://www.j-archive.com/media/2007-10-08_DJ_22a.jpg\" target=\"_blank\">burn out first</a> because it has the least amount of this to burn'                                                |\n",
      "|MUSIC              |'(<a href=\"http://www.j-archive.com/media/2008-01-17_J_04.jpg\" target=\"_blank\">Jon of the Clue Crew is playing bass.</a>)  You'll get an \"A\" for effort if you name this Italian musical term; <a href=\"http://www.j-archive.com/media/2008-01-17_J_04.mp3\">here's an example of one'                                                                                     |\n",
      "+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bkmpredict.filter(bkmpredict['prediction']==118).select('category','question').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
